{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import StatePreparation\n",
    "from qiskit.quantum_info import DensityMatrix, partial_trace\n",
    "from qclib.machine_learning.datasets import digits\n",
    "from qclib.state_preparation.util.baa import _split_combinations\n",
    "\n",
    "from qdna.compression import SchmidtCompressor\n",
    "from qdna.quantum_info import correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(vectors, num_data_qubits):\n",
    "    import matplotlib.pyplot as plt\n",
    "    _dpi = 96\n",
    "    matrix_dim_1 = 2**(int(np.ceil(num_data_qubits/2)))\n",
    "    matrix_dim_2 = 2**(int(np.floor(num_data_qubits/2)))\n",
    "\n",
    "    ncols = len(vectors)\n",
    "    _, axes = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=ncols,\n",
    "        figsize=(ncols*10*matrix_dim_1/_dpi, 10*matrix_dim_2/_dpi),\n",
    "        dpi=_dpi\n",
    "    )\n",
    "    for ax, vector in zip(axes, vectors):\n",
    "        ax.set_axis_off()\n",
    "        image = vector.reshape(matrix_dim_1, matrix_dim_2)\n",
    "        ax.imshow(image, cmap=plt.cm.gray, interpolation='none')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Experiment main routine\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an example of the circuit.\n",
    "def complete_circuit(n_qubits, state, compressor):\n",
    "    # Typical state initializer.\n",
    "    initializer = StatePreparation(state)\n",
    "\n",
    "    # Creates the quantum circuit.\n",
    "    circuit = QuantumCircuit(n_qubits)\n",
    "\n",
    "    # Circuit on Alice's side.\n",
    "    circuit.append(initializer.definition, range(n_qubits))\n",
    "    circuit.append(compressor.definition, range(n_qubits))\n",
    "    # circuit.reset(compressor.latent_qubits)\n",
    "\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(n_qubits, test_input, compressor, verbose=1):\n",
    "    # Applies the compression process to each of the test samples.\n",
    "\n",
    "    rhos = []\n",
    "\n",
    "    # Iterates through all test samples.\n",
    "    for i, test_sample in enumerate(np.concatenate([test_samples for _, test_samples in test_input.items()])):\n",
    "        circuit = complete_circuit(n_qubits, test_sample, compressor)\n",
    "\n",
    "        # Compares the trash state with the reference state |0>.\n",
    "        trash_state = np.array(\n",
    "            partial_trace(DensityMatrix(circuit), compressor.latent_qubits)\n",
    "        ).reshape(-1)\n",
    "        trash_state = np.concatenate([[np.real(e), np.imag(e)] for e in trash_state])\n",
    "\n",
    "        # Stores and prints the results.\n",
    "        rhos.append(trash_state)\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print(i, '-', rhos[-1])\n",
    "\n",
    "    return rhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Calculates the typical state\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the centroid.\n",
    "# Simply the average of the training samples (or a random selection of samples).\n",
    "def calculate_typical_state(n_qubits, training_input):\n",
    "    centroid = np.zeros(2**n_qubits)\n",
    "    for train_sample in np.concatenate([train_samples for _, train_samples in training_input.items()]):\n",
    "        centroid += train_sample\n",
    "\n",
    "    typical_state = centroid / np.linalg.norm(centroid)\n",
    "\n",
    "    return typical_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Find the best partitioning configuration.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_partitioning(n_qubits, typical_state, n_trash_partition, verbose=0):\n",
    "    n_latent_partition = n_qubits - n_trash_partition\n",
    "    min_entropy = np.iinfo(np.int32).max # 2147483648\n",
    "    for partition in _split_combinations(range(n_qubits), n_latent_partition):\n",
    "        set_a = set(partition)\n",
    "        set_b = set(range(n_qubits)).difference(set_a)\n",
    "        entropy = correlation(typical_state, set_a, set_b)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print('latent', set_a, 'trash', set_b, 'entropy', entropy)\n",
    "\n",
    "        if entropy <= min_entropy:\n",
    "            min_entropy = entropy\n",
    "            latent_partition = sorted(partition)\n",
    "            trash_partition = sorted(set(range(n_qubits)).difference(set(latent_partition)))\n",
    "\n",
    "    return latent_partition, trash_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Experiment\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import (\n",
    "    optim,\n",
    "    tensor,\n",
    "    float32,\n",
    "    no_grad,\n",
    "    complex64,\n",
    "    sum as sumt\n",
    ")\n",
    "\n",
    "# Define torch NN module\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Linear,\n",
    "    Sequential,\n",
    "    MSELoss,\n",
    "    CrossEntropyLoss,\n",
    "    CELU,\n",
    "    ReLU,\n",
    "    Sigmoid\n",
    ")\n",
    "\n",
    "class NeuralNet(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_stack = Sequential(\n",
    "            Linear(input_size, hidden_size, dtype=float32),\n",
    "            CELU(),\n",
    "            Linear(hidden_size, hidden_size, dtype=float32),\n",
    "            CELU(),\n",
    "            Linear(hidden_size, output_size, dtype=float32),\n",
    "            Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_stack(x)\n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_data(batch_size, x, y):\n",
    "    x_new, y_new = [], [],\n",
    "    for _ in range(batch_size):\n",
    "        n = np.random.randint(len(x))\n",
    "        x_new.append(x[n])\n",
    "        y_new.append(y[n])\n",
    "        \n",
    "    return (\n",
    "        tensor(np.array(x_new), dtype=float32),\n",
    "        tensor(np.array(y_new), dtype=float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target class: 0\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [3, 4]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0297\tAvg. Loss: 0.0212\n",
      "Performance on test data:\n",
      "\tLoss: 0.0000\n",
      "\tAccuracy: 100.0%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 100.0%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0245\tAvg. Loss: 0.0217\n",
      "Performance on test data:\n",
      "\tLoss: 0.0025\n",
      "\tAccuracy: 99.5%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 99.4%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0112\tAvg. Loss: 0.0222\n",
      "Performance on test data:\n",
      "\tLoss: 0.0083\n",
      "\tAccuracy: 99.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0098\tAvg. Loss: 0.0222\n",
      "Performance on test data:\n",
      "\tLoss: 0.0016\n",
      "\tAccuracy: 100.0%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 100.0%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0007\tAvg. Loss: 0.0215\n",
      "Performance on test data:\n",
      "\tLoss: 0.0055\n",
      "\tAccuracy: 99.5%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 99.4%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0033\tAvg. Loss: 0.0230\n",
      "Performance on test data:\n",
      "\tLoss: 0.0017\n",
      "\tAccuracy: 100.0%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 100.0%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0173\tAvg. Loss: 0.0227\n",
      "Performance on test data:\n",
      "\tLoss: 0.0028\n",
      "\tAccuracy: 99.5%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 99.4%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0040\tAvg. Loss: 0.0227\n",
      "Performance on test data:\n",
      "\tLoss: 0.0061\n",
      "\tAccuracy: 99.5%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 99.4%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.0004\tAvg. Loss: 0.0230\n",
      "Performance on test data:\n",
      "\tLoss: 0.0015\n",
      "\tAccuracy: 100.0%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 100.0%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0212\tAvg. Loss: 0.0218\n",
      "Performance on test data:\n",
      "\tLoss: 0.0063\n",
      "\tAccuracy: 99.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "target class: 1\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [3, 4]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0404\tAvg. Loss: 0.0610\n",
      "Performance on test data:\n",
      "\tLoss: 0.0683\n",
      "\tAccuracy: 90.5%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 91.1%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0681\tAvg. Loss: 0.0672\n",
      "Performance on test data:\n",
      "\tLoss: 0.0348\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0063\tAvg. Loss: 0.0710\n",
      "Performance on test data:\n",
      "\tLoss: 0.0523\n",
      "\tAccuracy: 92.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 93.3%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0648\tAvg. Loss: 0.0625\n",
      "Performance on test data:\n",
      "\tLoss: 0.0767\n",
      "\tAccuracy: 91.0%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 91.1%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0757\tAvg. Loss: 0.0614\n",
      "Performance on test data:\n",
      "\tLoss: 0.0674\n",
      "\tAccuracy: 91.0%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 91.6%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0053\tAvg. Loss: 0.0661\n",
      "Performance on test data:\n",
      "\tLoss: 0.0593\n",
      "\tAccuracy: 92.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 92.7%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0415\tAvg. Loss: 0.0638\n",
      "Performance on test data:\n",
      "\tLoss: 0.0336\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0809\tAvg. Loss: 0.0636\n",
      "Performance on test data:\n",
      "\tLoss: 0.0321\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.0537\tAvg. Loss: 0.0695\n",
      "Performance on test data:\n",
      "\tLoss: 0.0344\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0107\tAvg. Loss: 0.0643\n",
      "Performance on test data:\n",
      "\tLoss: 0.0405\n",
      "\tAccuracy: 96.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 97.2%\n",
      "target class: 2\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [0, 3]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0176\tAvg. Loss: 0.0760\n",
      "Performance on test data:\n",
      "\tLoss: 0.0926\n",
      "\tAccuracy: 88.4%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 87.7%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0170\tAvg. Loss: 0.0790\n",
      "Performance on test data:\n",
      "\tLoss: 0.0520\n",
      "\tAccuracy: 94.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0497\tAvg. Loss: 0.0783\n",
      "Performance on test data:\n",
      "\tLoss: 0.0480\n",
      "\tAccuracy: 95.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 95.5%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0857\tAvg. Loss: 0.0771\n",
      "Performance on test data:\n",
      "\tLoss: 0.0947\n",
      "\tAccuracy: 87.9%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 87.2%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0542\tAvg. Loss: 0.0795\n",
      "Performance on test data:\n",
      "\tLoss: 0.0657\n",
      "\tAccuracy: 92.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 92.2%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0042\tAvg. Loss: 0.0768\n",
      "Performance on test data:\n",
      "\tLoss: 0.0757\n",
      "\tAccuracy: 89.4%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 88.8%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0339\tAvg. Loss: 0.0801\n",
      "Performance on test data:\n",
      "\tLoss: 0.0496\n",
      "\tAccuracy: 94.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 95.0%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0946\tAvg. Loss: 0.0800\n",
      "Performance on test data:\n",
      "\tLoss: 0.0602\n",
      "\tAccuracy: 94.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.0845\tAvg. Loss: 0.0778\n",
      "Performance on test data:\n",
      "\tLoss: 0.0448\n",
      "\tAccuracy: 95.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 95.0%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0885\tAvg. Loss: 0.0769\n",
      "Performance on test data:\n",
      "\tLoss: 0.1157\n",
      "\tAccuracy: 83.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 82.7%\n",
      "target class: 3\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [0, 3]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0915\tAvg. Loss: 0.0780\n",
      "Performance on test data:\n",
      "\tLoss: 0.0539\n",
      "\tAccuracy: 93.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0691\tAvg. Loss: 0.0789\n",
      "Performance on test data:\n",
      "\tLoss: 0.0720\n",
      "\tAccuracy: 90.5%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 91.1%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0764\tAvg. Loss: 0.0770\n",
      "Performance on test data:\n",
      "\tLoss: 0.0470\n",
      "\tAccuracy: 93.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 95.0%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0618\tAvg. Loss: 0.0789\n",
      "Performance on test data:\n",
      "\tLoss: 0.0608\n",
      "\tAccuracy: 92.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 93.3%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0818\tAvg. Loss: 0.0787\n",
      "Performance on test data:\n",
      "\tLoss: 0.0750\n",
      "\tAccuracy: 89.9%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 90.5%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.1342\tAvg. Loss: 0.0790\n",
      "Performance on test data:\n",
      "\tLoss: 0.1057\n",
      "\tAccuracy: 85.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 86.0%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0899\tAvg. Loss: 0.0805\n",
      "Performance on test data:\n",
      "\tLoss: 0.0523\n",
      "\tAccuracy: 93.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0319\tAvg. Loss: 0.0800\n",
      "Performance on test data:\n",
      "\tLoss: 0.0460\n",
      "\tAccuracy: 94.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.1286\tAvg. Loss: 0.0781\n",
      "Performance on test data:\n",
      "\tLoss: 0.0520\n",
      "\tAccuracy: 93.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.1294\tAvg. Loss: 0.0770\n",
      "Performance on test data:\n",
      "\tLoss: 0.0341\n",
      "\tAccuracy: 96.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 75.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "target class: 4\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [4, 5]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0321\tAvg. Loss: 0.0448\n",
      "Performance on test data:\n",
      "\tLoss: 0.0229\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 96.6%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0302\tAvg. Loss: 0.0491\n",
      "Performance on test data:\n",
      "\tLoss: 0.0236\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.1194\tAvg. Loss: 0.0489\n",
      "Performance on test data:\n",
      "\tLoss: 0.0219\n",
      "\tAccuracy: 97.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 97.2%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0585\tAvg. Loss: 0.0496\n",
      "Performance on test data:\n",
      "\tLoss: 0.0259\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 97.2%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0325\tAvg. Loss: 0.0474\n",
      "Performance on test data:\n",
      "\tLoss: 0.0304\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0292\tAvg. Loss: 0.0472\n",
      "Performance on test data:\n",
      "\tLoss: 0.0199\n",
      "\tAccuracy: 97.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0390\tAvg. Loss: 0.0481\n",
      "Performance on test data:\n",
      "\tLoss: 0.0214\n",
      "\tAccuracy: 97.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0208\tAvg. Loss: 0.0478\n",
      "Performance on test data:\n",
      "\tLoss: 0.0174\n",
      "\tAccuracy: 98.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.0932\tAvg. Loss: 0.0478\n",
      "Performance on test data:\n",
      "\tLoss: 0.0157\n",
      "\tAccuracy: 97.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0424\tAvg. Loss: 0.0472\n",
      "Performance on test data:\n",
      "\tLoss: 0.0174\n",
      "\tAccuracy: 97.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "target class: 5\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [1, 2]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0885\tAvg. Loss: 0.0688\n",
      "Performance on test data:\n",
      "\tLoss: 0.0519\n",
      "\tAccuracy: 92.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 91.6%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0489\tAvg. Loss: 0.0668\n",
      "Performance on test data:\n",
      "\tLoss: 0.0320\n",
      "\tAccuracy: 96.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0327\tAvg. Loss: 0.0695\n",
      "Performance on test data:\n",
      "\tLoss: 0.0314\n",
      "\tAccuracy: 95.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0834\tAvg. Loss: 0.0678\n",
      "Performance on test data:\n",
      "\tLoss: 0.0429\n",
      "\tAccuracy: 94.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 93.3%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.1109\tAvg. Loss: 0.0676\n",
      "Performance on test data:\n",
      "\tLoss: 0.0258\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0626\tAvg. Loss: 0.0686\n",
      "Performance on test data:\n",
      "\tLoss: 0.0786\n",
      "\tAccuracy: 89.9%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 88.8%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0057\tAvg. Loss: 0.0644\n",
      "Performance on test data:\n",
      "\tLoss: 0.0351\n",
      "\tAccuracy: 95.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 95.5%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0679\tAvg. Loss: 0.0668\n",
      "Performance on test data:\n",
      "\tLoss: 0.0483\n",
      "\tAccuracy: 93.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 92.7%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.0284\tAvg. Loss: 0.0685\n",
      "Performance on test data:\n",
      "\tLoss: 0.0705\n",
      "\tAccuracy: 89.4%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 88.8%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0984\tAvg. Loss: 0.0684\n",
      "Performance on test data:\n",
      "\tLoss: 0.0729\n",
      "\tAccuracy: 90.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 89.9%\n",
      "target class: 6\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [3, 4]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0008\tAvg. Loss: 0.0269\n",
      "Performance on test data:\n",
      "\tLoss: 0.0133\n",
      "\tAccuracy: 97.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 97.2%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0000\tAvg. Loss: 0.0276\n",
      "Performance on test data:\n",
      "\tLoss: 0.0434\n",
      "\tAccuracy: 95.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 95.0%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0097\tAvg. Loss: 0.0274\n",
      "Performance on test data:\n",
      "\tLoss: 0.0067\n",
      "\tAccuracy: 99.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0085\tAvg. Loss: 0.0280\n",
      "Performance on test data:\n",
      "\tLoss: 0.0075\n",
      "\tAccuracy: 98.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0796\tAvg. Loss: 0.0261\n",
      "Performance on test data:\n",
      "\tLoss: 0.0117\n",
      "\tAccuracy: 98.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0103\tAvg. Loss: 0.0267\n",
      "Performance on test data:\n",
      "\tLoss: 0.0396\n",
      "\tAccuracy: 95.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 95.0%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0446\tAvg. Loss: 0.0271\n",
      "Performance on test data:\n",
      "\tLoss: 0.0076\n",
      "\tAccuracy: 99.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0355\tAvg. Loss: 0.0265\n",
      "Performance on test data:\n",
      "\tLoss: 0.0095\n",
      "\tAccuracy: 99.0%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.0331\tAvg. Loss: 0.0264\n",
      "Performance on test data:\n",
      "\tLoss: 0.0066\n",
      "\tAccuracy: 99.5%\n",
      "\tMCC: 1.0%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 100.0%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0008\tAvg. Loss: 0.0268\n",
      "Performance on test data:\n",
      "\tLoss: 0.0521\n",
      "\tAccuracy: 93.5%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 100.0%\n",
      "\tAccuracy 1: 92.7%\n",
      "target class: 7\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [3, 4]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0602\tAvg. Loss: 0.0522\n",
      "Performance on test data:\n",
      "\tLoss: 0.0271\n",
      "\tAccuracy: 97.5%\n",
      "\tMCC: 0.9%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 98.9%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.1049\tAvg. Loss: 0.0533\n",
      "Performance on test data:\n",
      "\tLoss: 0.0453\n",
      "\tAccuracy: 93.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 93.9%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0041\tAvg. Loss: 0.0526\n",
      "Performance on test data:\n",
      "\tLoss: 0.0271\n",
      "\tAccuracy: 96.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 97.8%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.0369\tAvg. Loss: 0.0510\n",
      "Performance on test data:\n",
      "\tLoss: 0.0289\n",
      "\tAccuracy: 96.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 75.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0190\tAvg. Loss: 0.0531\n",
      "Performance on test data:\n",
      "\tLoss: 0.0270\n",
      "\tAccuracy: 97.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.1089\tAvg. Loss: 0.0517\n",
      "Performance on test data:\n",
      "\tLoss: 0.0292\n",
      "\tAccuracy: 97.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 98.3%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0035\tAvg. Loss: 0.0513\n",
      "Performance on test data:\n",
      "\tLoss: 0.0507\n",
      "\tAccuracy: 94.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0283\tAvg. Loss: 0.0527\n",
      "Performance on test data:\n",
      "\tLoss: 0.0457\n",
      "\tAccuracy: 94.0%\n",
      "\tMCC: 0.7%\n",
      "\tAccuracy 0: 90.0%\n",
      "\tAccuracy 1: 94.4%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.1058\tAvg. Loss: 0.0532\n",
      "Performance on test data:\n",
      "\tLoss: 0.0251\n",
      "\tAccuracy: 97.0%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 70.0%\n",
      "\tAccuracy 1: 100.0%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.1105\tAvg. Loss: 0.0506\n",
      "Performance on test data:\n",
      "\tLoss: 0.0343\n",
      "\tAccuracy: 95.5%\n",
      "\tMCC: 0.8%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 97.2%\n",
      "target class: 8\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [3, 4]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.0398\tAvg. Loss: 0.0937\n",
      "Performance on test data:\n",
      "\tLoss: 0.0730\n",
      "\tAccuracy: 89.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 68.4%\n",
      "\tAccuracy 1: 92.2%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.0551\tAvg. Loss: 0.0957\n",
      "Performance on test data:\n",
      "\tLoss: 0.0831\n",
      "\tAccuracy: 86.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 68.4%\n",
      "\tAccuracy 1: 88.9%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0838\tAvg. Loss: 0.0932\n",
      "Performance on test data:\n",
      "\tLoss: 0.0651\n",
      "\tAccuracy: 93.0%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 63.2%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.1308\tAvg. Loss: 0.0941\n",
      "Performance on test data:\n",
      "\tLoss: 0.1146\n",
      "\tAccuracy: 81.9%\n",
      "\tMCC: 0.4%\n",
      "\tAccuracy 0: 73.7%\n",
      "\tAccuracy 1: 82.8%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.1044\tAvg. Loss: 0.0947\n",
      "Performance on test data:\n",
      "\tLoss: 0.0820\n",
      "\tAccuracy: 86.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 68.4%\n",
      "\tAccuracy 1: 88.9%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.1307\tAvg. Loss: 0.0950\n",
      "Performance on test data:\n",
      "\tLoss: 0.0532\n",
      "\tAccuracy: 93.5%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 68.4%\n",
      "\tAccuracy 1: 96.1%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0828\tAvg. Loss: 0.0924\n",
      "Performance on test data:\n",
      "\tLoss: 0.0697\n",
      "\tAccuracy: 89.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 68.4%\n",
      "\tAccuracy 1: 92.2%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0134\tAvg. Loss: 0.0951\n",
      "Performance on test data:\n",
      "\tLoss: 0.1029\n",
      "\tAccuracy: 84.4%\n",
      "\tMCC: 0.4%\n",
      "\tAccuracy 0: 73.7%\n",
      "\tAccuracy 1: 85.6%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.1285\tAvg. Loss: 0.0930\n",
      "Performance on test data:\n",
      "\tLoss: 0.0932\n",
      "\tAccuracy: 84.9%\n",
      "\tMCC: 0.4%\n",
      "\tAccuracy 0: 73.7%\n",
      "\tAccuracy 1: 86.1%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.0920\tAvg. Loss: 0.0933\n",
      "Performance on test data:\n",
      "\tLoss: 0.0973\n",
      "\tAccuracy: 85.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 73.7%\n",
      "\tAccuracy 1: 87.2%\n",
      "target class: 9\n",
      "\t trash qubits: 2\n",
      "\t\ttrash_partition: [3, 4]\n",
      "\t\trho_size: 32\n",
      "\t\trep: 0\n",
      "Training [100%]\tLoss: 0.1092\tAvg. Loss: 0.0978\n",
      "Performance on test data:\n",
      "\tLoss: 0.0744\n",
      "\tAccuracy: 88.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 65.0%\n",
      "\tAccuracy 1: 91.6%\n",
      "\t\trep: 1\n",
      "Training [100%]\tLoss: 0.1562\tAvg. Loss: 0.0982\n",
      "Performance on test data:\n",
      "\tLoss: 0.1184\n",
      "\tAccuracy: 84.9%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 95.0%\n",
      "\tAccuracy 1: 83.8%\n",
      "\t\trep: 2\n",
      "Training [100%]\tLoss: 0.0769\tAvg. Loss: 0.0966\n",
      "Performance on test data:\n",
      "\tLoss: 0.0913\n",
      "\tAccuracy: 86.4%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 86.6%\n",
      "\t\trep: 3\n",
      "Training [100%]\tLoss: 0.1010\tAvg. Loss: 0.0957\n",
      "Performance on test data:\n",
      "\tLoss: 0.1045\n",
      "\tAccuracy: 84.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 84.9%\n",
      "\t\trep: 4\n",
      "Training [100%]\tLoss: 0.0405\tAvg. Loss: 0.0954\n",
      "Performance on test data:\n",
      "\tLoss: 0.0652\n",
      "\tAccuracy: 90.5%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 70.0%\n",
      "\tAccuracy 1: 92.7%\n",
      "\t\trep: 5\n",
      "Training [100%]\tLoss: 0.0994\tAvg. Loss: 0.0951\n",
      "Performance on test data:\n",
      "\tLoss: 0.0780\n",
      "\tAccuracy: 90.5%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 91.6%\n",
      "\t\trep: 6\n",
      "Training [100%]\tLoss: 0.0704\tAvg. Loss: 0.0977\n",
      "Performance on test data:\n",
      "\tLoss: 0.0809\n",
      "\tAccuracy: 89.9%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 75.0%\n",
      "\tAccuracy 1: 91.6%\n",
      "\t\trep: 7\n",
      "Training [100%]\tLoss: 0.0768\tAvg. Loss: 0.0986\n",
      "Performance on test data:\n",
      "\tLoss: 0.0620\n",
      "\tAccuracy: 91.0%\n",
      "\tMCC: 0.6%\n",
      "\tAccuracy 0: 70.0%\n",
      "\tAccuracy 1: 93.3%\n",
      "\t\trep: 8\n",
      "Training [100%]\tLoss: 0.1318\tAvg. Loss: 0.0953\n",
      "Performance on test data:\n",
      "\tLoss: 0.1539\n",
      "\tAccuracy: 78.4%\n",
      "\tMCC: 0.4%\n",
      "\tAccuracy 0: 85.0%\n",
      "\tAccuracy 1: 77.7%\n",
      "\t\trep: 9\n",
      "Training [100%]\tLoss: 0.1076\tAvg. Loss: 0.0962\n",
      "Performance on test data:\n",
      "\tLoss: 0.1170\n",
      "\tAccuracy: 83.9%\n",
      "\tMCC: 0.5%\n",
      "\tAccuracy 0: 80.0%\n",
      "\tAccuracy 1: 84.4%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def full_experiment(class_label, n_trash_partition, reps=1):\n",
    "    # Dataset load.\n",
    "    seed = 42\n",
    "    _, training_input, test_input, class_labels = digits.load(\n",
    "        classes=[class_label],\n",
    "        training_size=150,\n",
    "        test_size=20,\n",
    "        random_seed=seed\n",
    "    )\n",
    "    \n",
    "    feature_dim = len(training_input[class_labels[0]][0])\n",
    "    n_qubits = int(np.ceil(np.log2(feature_dim)))\n",
    "\n",
    "    # Calculate the typical state.\n",
    "    typical_state = calculate_typical_state(n_qubits, training_input)\n",
    "\n",
    "    print('target class:', class_label)\n",
    "\n",
    "    # Search for the best partitioning.\n",
    "    _, trash_partition = find_partitioning(\n",
    "        n_qubits,\n",
    "        typical_state,\n",
    "        n_trash_partition,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    print('\\t', \"trash qubits:\", n_trash_partition)\n",
    "    print('\\t\\ttrash_partition:', trash_partition)\n",
    "\n",
    "    # Buld the compressor.\n",
    "    compressor = SchmidtCompressor(\n",
    "        typical_state,\n",
    "        opt_params={\n",
    "            'partition': trash_partition,\n",
    "            'lr': 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # CREATE THE DATASETS FROM THE EXTRACTED FEATURES\n",
    "\n",
    "    training_rhos = {}\n",
    "    test_rhos = {}\n",
    "\n",
    "    # Calculates the training dataset.\n",
    "    training_input[class_label] = np.array(list(training_input[class_label]) * 9) # balance dataset\n",
    "    training_rhos[0] = experiment(\n",
    "        n_qubits,\n",
    "        training_input,\n",
    "        compressor,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calculate test density matrices.\n",
    "    test_rhos[0] = experiment(\n",
    "        n_qubits,\n",
    "        test_input,\n",
    "        compressor,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Calculate density matrices to the other classes.\n",
    "    training_rhos[1] = []\n",
    "    test_rhos[1] = []\n",
    "    for i in [j for j in range(10) if j not in class_labels]:\n",
    "        # Dataset load.\n",
    "        _, _training_input, _test_input, _ = digits.load(\n",
    "            classes=[i],\n",
    "            training_size=150,\n",
    "            test_size=20,\n",
    "            random_seed=seed\n",
    "        )\n",
    "\n",
    "        training_rhos[1].extend(\n",
    "            experiment(\n",
    "                n_qubits,\n",
    "                _training_input,\n",
    "                compressor,\n",
    "                verbose=0\n",
    "            )\n",
    "        )\n",
    "\n",
    "        test_rhos[1].extend(\n",
    "            experiment(\n",
    "                n_qubits,\n",
    "                _test_input,\n",
    "                compressor,\n",
    "                verbose=0\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # FORMAT DATA\n",
    "\n",
    "    # Format the training and test data.\n",
    "    train_data = np.concatenate([\n",
    "        [rho] for m in range(len(training_rhos)) for rho in training_rhos[m]\n",
    "    ])\n",
    "    test_data = np.concatenate([\n",
    "        [rho] for m in range(len(test_rhos)) for rho in test_rhos[m]\n",
    "    ])\n",
    "\n",
    "    # Format the training and test labels.\n",
    "    train_targets = np.concatenate([\n",
    "        [m] * len(training_rhos[m]) for m in range(len(training_rhos))\n",
    "    ])\n",
    "    test_targets = np.concatenate([\n",
    "        [m] * len(test_rhos[m]) for m in range(len(test_rhos))\n",
    "    ])\n",
    "\n",
    "    rho_size = len(train_data[0])\n",
    "    print('\\t\\trho_size:', rho_size)\n",
    "    \n",
    "    total_losses = []\n",
    "    tps = []\n",
    "    tns = []\n",
    "    total_ps = []\n",
    "    total_ns = []\n",
    "    accs = []\n",
    "    fps = []\n",
    "    fns = []\n",
    "    f1s = []\n",
    "    mccs = []\n",
    "\n",
    "\n",
    "    # REPEAT THE WHOLE TRAINING+TESTING PROCESS `reps` TIMES\n",
    "    #\n",
    "    # This process uses the datasets created from the features\n",
    "    # extracted using the Schmidt Compressor.\n",
    "\n",
    "    for rep in range(reps):\n",
    "        print('\\t\\trep:', rep)\n",
    "        \n",
    "        # TRAINING\n",
    "        \n",
    "        model  = NeuralNet(rho_size, 3*rho_size, 1)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        loss_func = MSELoss()\n",
    "\n",
    "        loss_list = []  # Store loss history\n",
    "        model.train()   # Set model to training mode\n",
    "\n",
    "        iters = 1000\n",
    "        batch_size = 25\n",
    "        for i in range(iters):\n",
    "            # Random sampling of data.\n",
    "            x_batch, y_batch = new_data(batch_size, train_data, train_targets)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True) # Initialize gradient\n",
    "            output = model(x_batch)               # Forward pass\n",
    "            loss = loss_func(output, y_batch)     # Calculate loss\n",
    "            loss.backward()                       # Backward pass\n",
    "            optimizer.step()                      # Optimize weights\n",
    "\n",
    "            loss_list.append(loss.item())         # Store loss\n",
    "\n",
    "        print(\n",
    "            f\"Training [{100.0 * (i + 1) / iters:.0f}%]\\t\"\n",
    "            f\"Loss: {loss_list[-1]:.4f}\\t\"\n",
    "            f\"Avg. Loss: {sum(loss_list) / len(loss_list):.4f}\"\n",
    "        )\n",
    "\n",
    "        # TESTING\n",
    "\n",
    "        total_loss = []\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        total_p = 0\n",
    "        total_n = 0\n",
    "        acc = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        f1 = 0\n",
    "        mcc = 0\n",
    "\n",
    "        model.eval()  # set model to evaluation mode\n",
    "        with no_grad():\n",
    "            for (data, target) in zip(test_data, test_targets):\n",
    "                data = tensor(data, dtype=float32)\n",
    "                target = tensor([target], dtype=float32)\n",
    "\n",
    "                output = model(data)\n",
    "\n",
    "                pred = np.round(output, 0)\n",
    "\n",
    "                if pred == target:\n",
    "                    if pred == 0:\n",
    "                        tp += 1\n",
    "                    else:\n",
    "                        tn += 1\n",
    "                \n",
    "                if pred != target:\n",
    "                    if pred == 0:\n",
    "                        fp += 1\n",
    "                    else:\n",
    "                        fn += 1\n",
    "\n",
    "                if target == 0:\n",
    "                    total_p += 1\n",
    "                else:\n",
    "                    total_n += 1\n",
    "\n",
    "                loss = loss_func(output, target)\n",
    "                total_loss.append(loss.item())\n",
    "\n",
    "            acc = (tp+tn) / (total_p+total_n)\n",
    "\n",
    "            f1 = (2*tp) / (2*tp+fp+fn)\n",
    "\n",
    "            mcc = (tp*tn - fp*fn) / np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "\n",
    "            print(\n",
    "                \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\t\"\n",
    "                \"Accuracy: {:.1f}%\\n\\t\"\n",
    "                \"MCC: {:.1f}%\\n\\t\"\n",
    "                \"Accuracy 0: {:.1f}%\\n\\t\"\n",
    "                \"Accuracy 1: {:.1f}%\".format(\n",
    "                    sum(total_loss) / (total_p+total_n),\n",
    "                    acc * 100,\n",
    "                    mcc,\n",
    "                    tp / total_p * 100,\n",
    "                    tn / total_n * 100\n",
    "                )\n",
    "            )\n",
    "\n",
    "        total_losses.append(sum(total_loss))\n",
    "        tps.append(tp)\n",
    "        tns.append(tn)\n",
    "        total_ps.append(total_p)\n",
    "        total_ns.append(total_n)\n",
    "        accs.append(acc)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        f1s.append(f1)\n",
    "        mccs.append(mcc)\n",
    "\n",
    "    return (total_losses, tps, tns, accs, fps, fns, f1s, mccs)\n",
    "\n",
    "results = {}\n",
    "for class_label in range(0, 10):\n",
    "    results[class_label] = full_experiment(class_label, n_trash_partition=2, reps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| class | avg. TP | std. TP | avg. TN | std. TN | avg. FP | std. FP | avg. FN | std. FN | avg. acc | std. acc | avg. F1 | std. F1 | avg. MCC | std. MCC |\n",
       "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
       "| 0 | 20.0 | 0.0 | 178.2 | 0.7483314773547882 | 0.8 | 0.7483314773547882 | 0.0 | 0.0 | 0.996 | 0.0038 | 0.9807 | 0.0179 | 0.9789 | 0.0195 |\n",
       "| 1 | 17.1 | 0.3 | 169.7 | 5.235456045083369 | 9.3 | 5.23545604508337 | 2.9 | 0.3 | 0.9387 | 0.0257 | 0.7462 | 0.0803 | 0.7238 | 0.0831 |\n",
       "| 2 | 18.7 | 0.45825756949558394 | 163.4 | 7.49933330370107 | 15.6 | 7.4993333037010705 | 1.3 | 0.45825756949558394 | 0.9151 | 0.0367 | 0.7006 | 0.0851 | 0.6877 | 0.081 |\n",
       "| 3 | 16.3 | 0.6403124237432849 | 167.1 | 5.80430874437258 | 11.9 | 5.80430874437258 | 3.7 | 0.6403124237432849 | 0.9216 | 0.0265 | 0.6845 | 0.0626 | 0.6565 | 0.0626 |\n",
       "| 4 | 19.0 | 0.6324555320336759 | 174.2 | 1.4000000000000001 | 4.8 | 1.4000000000000001 | 1.0 | 0.6324555320336759 | 0.9709 | 0.0054 | 0.8681 | 0.0207 | 0.8566 | 0.0214 |\n",
       "| 5 | 18.8 | 1.077032961426901 | 166.7 | 5.657738063926255 | 12.3 | 5.657738063926255 | 1.2 | 1.0770329614269007 | 0.9322 | 0.0252 | 0.7436 | 0.0665 | 0.7321 | 0.0632 |\n",
       "| 6 | 19.8 | 0.39999999999999997 | 174.3 | 4.001249804748511 | 4.7 | 4.001249804748512 | 0.2 | 0.4000000000000001 | 0.9754 | 0.0193 | 0.8965 | 0.0711 | 0.891 | 0.0719 |\n",
       "| 7 | 16.6 | 1.2 | 173.9 | 3.6455452267116364 | 5.1 | 3.6455452267116364 | 3.4 | 1.2 | 0.9573 | 0.0149 | 0.8003 | 0.0505 | 0.7824 | 0.0546 |\n",
       "| 8 | 13.3 | 0.6403124237432849 | 161.3 | 7.642643521714199 | 18.7 | 7.642643521714199 | 5.7 | 0.6403124237432849 | 0.8774 | 0.0357 | 0.5324 | 0.0693 | 0.4904 | 0.0706 |\n",
       "| 9 | 15.8 | 1.7204650534085253 | 157.2 | 8.749857141690942 | 21.8 | 8.749857141690942 | 4.2 | 1.7204650534085253 | 0.8693 | 0.038 | 0.5563 | 0.0533 | 0.5234 | 0.0508 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display, Latex\n",
    "\n",
    "table = '| class | avg. TP | std. TP | avg. TN | std. TN | avg. FP | std. FP | avg. FN | std. FN | avg. acc | std. acc | avg. F1 | std. F1 | avg. MCC | std. MCC |\\n'\n",
    "table += '|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\\n'\n",
    "for class_label in range(0, 10):\n",
    "    result = results[class_label]\n",
    "    avg_total_loss = np.mean(result[0])\n",
    "    std_total_loss = np.std(result[0])\n",
    "\n",
    "    avg_tp = np.mean(result[1])\n",
    "    std_tp = np.std(result[1])\n",
    "\n",
    "    avg_tn = np.mean(result[2])\n",
    "    std_tn = np.std(result[2])\n",
    "\n",
    "    avg_acc = np.mean(result[3])\n",
    "    std_acc = np.std(result[3])\n",
    "\n",
    "    avg_fp = np.mean(result[4])\n",
    "    std_fp = np.std(result[4])\n",
    "\n",
    "    avg_fn = np.mean(result[5])\n",
    "    std_fn = np.std(result[5])\n",
    "\n",
    "    avg_f1 = np.mean(result[6])\n",
    "    std_f1 = np.std(result[6])\n",
    "\n",
    "    avg_mcc = np.mean(result[7])\n",
    "    std_mcc = np.std(result[7])\n",
    "\n",
    "    table += f'| {class_label} | {avg_tp} | {std_tp} | {avg_tn} | {std_tn} | {avg_fp} | {std_fp} | {avg_fn} | {std_fn} | {round(avg_acc, 4)} | {round(std_acc, 4)} | {round(avg_f1, 4)} | {round(std_f1, 4)} | {round(avg_mcc, 4)} | {round(std_mcc, 4)} |\\n'\n",
    "\n",
    "display(Markdown(table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

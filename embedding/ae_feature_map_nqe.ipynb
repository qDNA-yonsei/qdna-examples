{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import tensor, float32\n",
    "\n",
    "# pip install -U qdna-lib\n",
    "from qdna.embedding import (\n",
    "    NqeAeFeatureMap, \n",
    "    NqeZZFeatureMap\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qclib.machine_learning.datasets import digits\n",
    "\n",
    "# Dataset load.\n",
    "seed = 42\n",
    "\n",
    "# Here you can choose the dataset classes. For example: [0,1], [1,8], [2,4], etc.\n",
    "_, training_input, test_input, class_labels = digits.load(\n",
    "    classes=[0, 1],\n",
    "    training_size=150,\n",
    "    test_size=20,\n",
    "    random_seed=seed\n",
    ")\n",
    "\n",
    "feature_dim = len(training_input[class_labels[0]][0])\n",
    "num_qubits = int(np.ceil(np.log2(feature_dim)))\n",
    "\n",
    "# The `digits.load()` function does not return the data as expected by NQE.\n",
    "# Because of this, we need to do a simple rearrangement as follows.\n",
    "\n",
    "# Format the data for NQE's `fit` and `transform` functions.\n",
    "train_data = np.array(\n",
    "    training_input[class_labels[0]] + \\\n",
    "    training_input[class_labels[1]]\n",
    ")\n",
    "\n",
    "test_data = np.array(\n",
    "    test_input[class_labels[0]] + \\\n",
    "    test_input[class_labels[1]]\n",
    ")\n",
    "\n",
    "# Target labels.\n",
    "train_targets = np.array(\n",
    "    [class_labels[0]] * len(training_input[class_labels[0]]) + \\\n",
    "    [class_labels[1]] * len(training_input[class_labels[1]])\n",
    ")\n",
    "\n",
    "test_targets = np.array(\n",
    "    [class_labels[0]] * len(test_input[class_labels[0]]) + \\\n",
    "    [class_labels[1]] * len(test_input[class_labels[1]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(feature_dim)\n",
    "print(num_qubits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Quantum Embedding (NQE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [10%]\tLoss: 0.0011\tAvg. Loss: 0.0011\n",
      "Training [20%]\tLoss: 0.0000\tAvg. Loss: 0.0005\n",
      "Training [30%]\tLoss: 0.0000\tAvg. Loss: 0.0004\n",
      "Training [40%]\tLoss: 0.0000\tAvg. Loss: 0.0003\n",
      "Training [50%]\tLoss: 0.0000\tAvg. Loss: 0.0002\n",
      "Training [60%]\tLoss: 0.0000\tAvg. Loss: 0.0002\n",
      "Training [70%]\tLoss: 0.0000\tAvg. Loss: 0.0002\n",
      "Training [80%]\tLoss: 0.0000\tAvg. Loss: 0.0001\n",
      "Training [90%]\tLoss: 0.0000\tAvg. Loss: 0.0001\n",
      "Training [100%]\tLoss: 0.0000\tAvg. Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Create a trainable amplitude encoding feature map\n",
    "t_fmap = NqeAeFeatureMap(num_qubits, reps=1, set_global_phase=True)\n",
    "\n",
    "# Pre-training the embedding.\n",
    "t_fmap.fit(train_data, train_targets, iters=10)\n",
    "\n",
    "# Tranforms the original dataset (using trained feature map)\n",
    "train_nqe = t_fmap.transform(tensor(train_data, dtype=float32))\n",
    "test_nqe = t_fmap.transform(tensor(test_data, dtype=float32))\n",
    "\n",
    "# From now on, the trace distance of data with different labels is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1649951  -0.34003606  0.12849116 ... -0.01313476 -0.06123468\n",
      "  -0.31228036]\n",
      " [ 0.14164735 -0.31942713  0.11426534 ... -0.01206358 -0.06594189\n",
      "  -0.30632454]\n",
      " [ 0.16070811 -0.33201817  0.13078459 ... -0.00160599 -0.06941289\n",
      "  -0.31027117]\n",
      " ...\n",
      " [ 0.16053954 -0.3372686   0.11936585 ... -0.0049169  -0.06335965\n",
      "  -0.32194883]\n",
      " [ 0.15774992 -0.3239718   0.11463089 ... -0.00721916 -0.06513025\n",
      "  -0.30494064]\n",
      " [ 0.15700172 -0.32119817  0.11222707 ... -0.00219209 -0.06597438\n",
      "  -0.30045938]]\n"
     ]
    }
   ],
   "source": [
    "print(train_nqe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16798161 -0.3449557   0.13013968 ... -0.00406188 -0.06959986\n",
      "  -0.30671495]\n",
      " [ 0.15224478 -0.32395446  0.11761674 ...  0.00194404 -0.06834033\n",
      "  -0.30400974]\n",
      " [ 0.15287742 -0.3305541   0.11626966 ...  0.00098379 -0.07155859\n",
      "  -0.3025763 ]\n",
      " ...\n",
      " [ 0.14758082 -0.30902207  0.11330259 ... -0.006437   -0.0658424\n",
      "  -0.27589327]\n",
      " [ 0.16965239 -0.34798557  0.13330437 ...  0.00511582 -0.07081909\n",
      "  -0.32408315]\n",
      " [ 0.15052529 -0.3271492   0.12427101 ... -0.01104955 -0.06896384\n",
      "  -0.30707955]]\n"
     ]
    }
   ],
   "source": [
    "print(test_nqe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
